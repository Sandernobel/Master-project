{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advanced-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scientific-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHolder(pd.DataFrame):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, multivariate=True):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        print(2)\n",
    "        super().__init__(data=pd.read_csv(path, index_col=0))\n",
    "        print(3)\n",
    "        self.X_transformer = None\n",
    "        self.y_transformer = None\n",
    "        self.multivariate = multivariate\n",
    "        \n",
    "    def handle_na(self, data):\n",
    "        \"\"\"\n",
    "        Handles missing values\n",
    "        \"\"\"\n",
    "\n",
    "        # Interpolate NA's where possible, keeping sequence in mind\n",
    "        data.interpolate(limit_direction='forward', limit_area='inside', inplace=True)\n",
    "\n",
    "        # Drop rest of rows with NA's\n",
    "        data.dropna(inplace=True)\n",
    "        \n",
    "        X = data.drop(TARGET, axis=1)\n",
    "        y = data[TARGET]\n",
    "        \n",
    "        return X, y\n",
    "            \n",
    "        \n",
    "    def preprocess(self, val=True):\n",
    "        \"\"\"\n",
    "        Function to take care of preprocessing steps\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse time data and split features and target\n",
    "        self['date'] = pd.to_datetime(self[TIME_COLS])\n",
    "        self.drop(TIME_COLS, axis=1, inplace=True)\n",
    "        self.set_index('date', inplace=True)\n",
    "        \n",
    "        X = self.drop(TARGET, axis=1)\n",
    "        y = self[TARGET]\n",
    "        \n",
    "        # First split data before doing anything else\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "        X_val, y_val = None, None\n",
    "        if val:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2/0.8, shuffle=False)\n",
    "            X_val, y_val = self.handle_na(pd.concat([X_val, y_val], axis=1))\n",
    "\n",
    "        # Impute NA's and delete rest of NA's\n",
    "        X_train, y_train = self.handle_na(pd.concat([X_train, y_train], axis=1))\n",
    "        X_test, y_test = self.handle_na(pd.concat([X_test, y_test], axis=1))\n",
    "                \n",
    "        # Normalize numerical values and one hot encode categorical values\n",
    "        self.X_transformer = make_column_transformer(\n",
    "           (StandardScaler(),\n",
    "            make_column_selector(dtype_include=np.number)),  \n",
    "           (OneHotEncoder(),\n",
    "            make_column_selector(dtype_include=object))\n",
    "        )\n",
    "        self.y_transformer = MinMaxScaler()\n",
    "        \n",
    "        # Fit scalers on train data and transform rest of data as well\n",
    "        X_train = self.X_transformer.fit_transform(X_train)\n",
    "        X_val = self.X_transformer.transform(X_val)\n",
    "        X_test = self.X_transformer.transform(X_test)\n",
    "        \n",
    "        y_train = self.y_transformer.fit_transform(np.array(y_train).reshape(-1,1))\n",
    "        y_val = self.y_transformer.transform(np.array(y_val).reshape(-1,1))\n",
    "        y_test = self.y_transformer.transform(np.array(y_test).reshape(-1,1))\n",
    "        \n",
    "        # If univariate, X = y\n",
    "        if not self.multivariate:\n",
    "            X_train = y_train\n",
    "            X_val = y_val\n",
    "            X_test = y_test\n",
    "        \n",
    "        return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "threaded-harris",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cell with hyperparameters and arguments\n",
    "The contents of this cell will have to be specified in the command line at the end\n",
    "\"\"\"\n",
    "\n",
    "DATA_PATH = 'PM_data.csv'\n",
    "TARGET = 'pm2.5'\n",
    "TIME_COLS = ['year', 'month', 'day', 'hour']\n",
    "MULTIVARIATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ranging-brunei",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "df = DataHolder(DATA_PATH, MULTIVARIATE)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = df.preprocess()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
